<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Towards Zero-Shot Generation of NeRFs from Texts.">
  <meta name="keywords" content="Text to 3D, Neural Field, HyperNetwork">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>HyperFields</title>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <!-- <link rel="icon" href="./static/images/favicon.ico"> -->

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://3dl.cs.uchicago.edu/">
        <span class="threedle-icon"></span>
      </a>
      <a class="navbar-item" href="https://pals.ttic.edu/">
        <span class="pals-icon"></span>
      </a>
    </div>

  </div>
</nav>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title"><span style="text-shadow: 2px 2px 0px #CCFF00">HyperFields</span>:Towards Zero-Shot Generation of NeRFs from Texts. </h1>
          <!--<h1 class="is-size-4 publication-title">CVPR 2023 (Highlight)</h1> -->
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://people.cs.uchicago.edu/~sudarshan/">Sudarshan Babu</a><sup>*&#8224 </sup>,</span>
            <span class="author-block">
              <a href="https://rgliu.com/">Richard Liu</a><sup>*&#8225 </sup>,</span>
            <span class="author-block">
              <a href="https://github.com/AveryZhou">Avery Zhou</a><sup>*&#8224</sup>,</span>
            <span class="author-block">
              <a href="https://people.cs.uchicago.edu/~mmaire/">Michael Maire</a><sup> &#8225</sup>,</span>
            <span class="author-block">
              <a href="https://home.ttic.edu/~gregory/">Greg Shakhnarovich</a><sup>&#8224</sup>,</span>
            <span class="author-block">
              <a href="https://people.cs.uchicago.edu/~ranahanocka/">Rana Hanocka</a><sup>&#8225</sup>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup> * </sup>Equal Contribution</span>
            <span class="author-block"><sup> &#8224 </sup>Toyota Technological Institute at Chicago</span>
            <span class="author-block"><sup> &#8225 </sup>University of Chicago</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <!-- arXiv Link. -->
              <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Video Link. 
              <span class="link-block">
                <a href="https://www.youtube.com/watch?v=OKPySDDCdd0"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span>
              -->
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/threedle/hyperfields"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <image id="teaser">
        <img src="./static/images/figures/HyperFields_teaser_final.png"
                type="image/png">
      </image>
      <h2 class="subtitle has-text-centered">
         HyperFields is a hypernetwork that learns to map text to the space of the weights of a neural radiance field (first
column). On learning such a mapping HyperFields is capable of generating in-distrubtion scenes (unseen during training) in
a feed forward manner (second column), and for unseen out-of-distribution prompts HyperFields converges to those scenes
with just a few gradient steps (third column).

      </h2>
    </div>
  </div>
</section>

<section class="hero is-light is-small">
  <div class="hero-body">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">All Scenes Generated by a Single HyperFields Network</h2>
    </div>
    </div>
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-chair-plaid">
            <video poster="" id="chair-plaid" autoplay muted loop playsinline height="100%">
                <source src="./static/videos/plaid_chair.mp4" type="video/mp4">
            </video>
            <p class="has-text-centered">Plaid Chair</p>
        </div>
        <div class="item item-chair-terracotta">
            <video poster="" id="chair-terracotta" autoplay muted loop playsinline height="100%">
                <source src="./static/videos/terracotta_chair.mp4" type="video/mp4">
            </video>
            <p class="has-text-centered">Terracotta Chair</p>
        </div>


	<div class="item item-toaster-plaid">
          <video poster="" id="toaster-plaid" autoplay muted loop playsinline height="100%">
            <source src="./static/videos/plaid_toaster.mp4" type="video/mp4">
          </video>
          <p class="has-text-centered">Plaid Toaster</p>
        </div>
        <div class="item item-chair-stained">
            <video poster="" id="chair-stained" autoplay muted loop playsinline height="100%">
                <source src="./static/videos/stained_chair.mp4" type="video/mp4">
            </video>
            <p class="has-text-centered">Stained Glass Chair</p>
        </div>
        <div class="item item-toaster-tiger">
            <video poster="" id="toaster-tiger" autoplay muted loop playsinline height="100%">
                <source src="./static/videos/tiger_toaster.mp4" type="video/mp4">
            </video>
            <p class="has-text-centered">Toaster made of Tiger Stripes</p>
        </div>
        <div class="item item-toaster-stained">
            <video poster="" id="toaster-stained" autoplay muted loop playsinline height="100%">
                <source src="./static/videos/stained_toaster.mp4" type="video/mp4">
            </video>
            <p class="has-text-centered">Stained Glass Toaster</p>
        </div>
        <div class="item item-pot-plaid">
            <video poster="" id="pot-plaid" autoplay muted loop playsinline height="100%">
                <source src="./static/videos/plaid_pot.mp4" type="video/mp4">
            </video>
            <p class="has-text-centered">Plaid Pot</p>
        </div>
        <div class="item item-pot-stained">
            <video poster="" id="pot-stained" autoplay muted loop playsinline height="100%">
              <source src="./static/videos/stained_pot.mp4" type="video/mp4">
            </video>
            <p class="has-text-centered">Stained Glass Pot</p>
        </div>
        <div class="item item-plaid-bench">
            <video poster="" id="plaid-bench" autoplay muted loop playsinline height="100%">
                <source src="./static/videos/plaid_bench.mp4" type="video/mp4">
            </video>
            <p class="has-text-centered">Plaid Bench</p>
        </div>
        <div class="item item-stained-bench">
            <video poster="" id="stained-bench" autoplay muted loop playsinline height="100%">
                <source src="./static/videos/stained_glass_bench.mp4" type="video/mp4">
            </video>
            <p class="has-text-centered">Stained Glass Bench</p>
        </div>


      </div>
    </div>
  </div>
</section>
<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
           We introduce HyperFields, a method for generating text-conditioned NeRFs with a single forward pass or with some finetuning. Key to our approach is (i) a dynamic hypernetwork, which learns a smooth mapping from text token embeddings to the space of neural radiance fields; (ii) NeRF distillation training in which we distill scenes encoded in individual NeRFs into one dynamic hypernetwork. We demonstrate that through the above techniques, the network is able to fit over a hundred unique scenes. We further demonstrate that HyperFields learns a more general map between text and NeRFs, and consquently is capable of predicting novel in-distribution and out-of-distribution scenes either zero-shot or with a few finetuning steps. HyperFields finetuning benefits from accelerated convergence thanks to the learned general map, and is capable of synthesizing novel scenes 5 to 10 times faster than existing neural-optimization based methods. We finally demonstrate that the learned representation is smooth, through smooth interpolation of text latents across different NeRF scenes.

          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->

    <!-- Overview. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <hr class="divider" />
        <h2 class="title is-3">Network Overview</h2>
        <div class="overview-image">
          <img src="./static/images/figures/overview.jpg" type="image/jpg">
        </div>
        <div class="content has-text-justified">
          <p>
          The input to the HyperFields system is a text prompt, which is encoded into latents
by a pre-trained text encoder, which in our case is a frozen BERT model. The text latents are passed to a Transformer
module, which outputs a conditioning token (CT). This conditioning token (which supplies scene information) is used to
condition each of the MLP modules in the hypernetwork. The first hypernetwork MLP (on the left) predicts the weights W1
of the first layer of the NeRF MLP, which is the standard NeRF neural architecture that actually encodes and synthesizes
the desired scene. The second hypernetwork MLP then takes as input both the CT as well as a1, which are the activations
from the first predicted NeRF MLP layer, and predicts the weights W2 of the second NeRF MLP. The subsequence scene-
conditioned hypernetwork MLPs follow the same pattern, taking the activations ai−1 from the previous predicted NeRF
MLP layer as input to generate weights Wi for the ith layer of the NeRF MLP. We also introduce stop gradients (SG)
during hypernetwork training so that gradients are not backpropoagated through the activations of the predicted NeRF layers.
The dynamic hypernetwork system allows our model to dynamically update for a given scene input (text prompt) and 3D
coordinate input processed by the NeRF MLP
                     </p>
        </div>

      </div>
    </div>
    <!--/ Overview. -->

    <!-- Semantic Highlighting. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <hr class="divider" />
        <h2 class="title is-3">Zero-Shot Generalization</h2>
        <div class="content has-text-justified">
          <p>
Zero Shot In-Distribution Generalization. Faded objects are the results of HyperFields on prompts used during
training, and opaque objects are results on unseen prompts. Note that all results are obtained in a single feedforward manner
(i.e. no test time optimization). All types of shapes and colors are seen during training, however during inference we present
novel unseen combinations (e.g. “red chair” is unseen during training but the model trains on the color “red” and the shape
“chair”.
          </p>
        </div>
        <div class="overview-image">
        <img src="./static/images/figures/faded_generalization.jpg" type="image/jpg">
        </div>

      </div>
    </div>
    <!--/ Semantic Highlighting. -->

    <!-- Applications. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <hr class="divider" />
        <h2 class="title is-3">Faster Generation of scenes with  unseen Geometry and/or Attribute</h2>
        <div class="content has-text-justified">
          <p>
          Our method generates scenes that capture the given out-of-distribution prompt in at most 2k steps (row 1), whereas baseline models are far from  the desired scene at the same number of steps (row 2 and 4). When allowed to fine-tune for longer (row 3 and 5) the quality of baseline’s generations are worse or at best comparable to our model’s generations despite our model being fine tuned for significantly fewer steps. Demonstrating our model’s ability to adapt better to unseen shapes and attributes.

          </p>
        </div>        
        <div class="odd-image">
          <img src="./static/images/figures/ood_result.png" type="image/png">
        </div>
      </div>
    </div>
    </div>
    <!--/ Applications. -->


<!--
<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@InProceedings{decatur2022highlighter,
  author    = {Decatur, Dale and Lang, Itai and Hanocka, Rana},
  title     = {3D Highlighter: Localizing Regions on 3D Shapes via Text Descriptions},
  journal   = {CVPR},
  year      = {2022},
}</code></pre>
  </div>
</section>
-->

<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link" href="https://github.com/threedle/hyperfields" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license" href="https://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            Parts of the code for this website are reused from the <a href="https://github.com/nerfies/nerfies.github.io">source code</a> contributed by the authors of <a href="https://nerfies.github.io/">Nerfies</a>.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
